{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Defensive Programming</h1>\n",
    "<p><img src=\"images/1line.png\" dwidth=100% /></p>\n",
    "\n",
    "\n",
    "<p>Our previous lessons have introduced the basic tools of programming: variables and lists, file I/O, loops, conditionals, functions and OOP. What they <em>haven&rsquo;t</em> done is show us how to tell whether a program is getting the right answer, and how to tell if it&rsquo;s <em>still</em> getting the right answer as we make changes to it.</p>\n",
    "<p>To achieve that, we need to:</p>\n",
    "<ul>\n",
    "<li>Write programs that check their own operation.</li>\n",
    "<li>Write and run tests for widely-used functions.</li>\n",
    "<li>Make sure we know what &ldquo;correct&rdquo; actually means.</li>\n",
    "</ul>\n",
    "<p>The good news is, doing these things will speed up our programming, not slow it down.</p>\n",
    "\n",
    "<h2 id=\"assertions\">Assertions</h2>\n",
    "<ul>\n",
    "<li>The first step toward getting the right answers from our programs is to assume that mistakes <em>will</em> happen and to guard against them.</li>\n",
    "<li>This is called defensive programming, and the most common way to do it is to add assertions to our code so that it checks itself as it runs.</li>\n",
    "<li>An assertion is simply a statement that something must be true at a certain point in a program.</li>\n",
    "<li>When Python sees one, it evaluates the assertion&rsquo;s condition.</li>\n",
    "<li>If it&rsquo;s true, Python does nothing, but if it&rsquo;s false, Python halts the program immediately and prints the error message if one is provided.</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Data should only contain positive values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m num \u001b[39min\u001b[39;00m numbers:\n\u001b[1;32m----> 4\u001b[0m     \u001b[39massert\u001b[39;00m num \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mData should only contain positive values\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m num\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtotal is:\u001b[39m\u001b[39m'\u001b[39m, total)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Data should only contain positive values"
     ]
    }
   ],
   "source": [
    "numbers = [1.5, 2.3, 0.7, -0.001, 4.4]\n",
    "total = 0.0\n",
    "for num in numbers:\n",
    "    assert num > 0.0, 'Data should only contain positive values'\n",
    "    total += num\n",
    "print('total is:', total)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Programs like the Firefox browser are full of assertions: 10-20% of the code they contain are there to check that the other 80&ndash;90% are working correctly.</li>\n",
    "<li>Broadly speaking, assertions fall into three categories:\n",
    "<ul>\n",
    "<li>A <strong>precondition</strong> is something that must be true at the start of a function in order for it to work correctly.</li>\n",
    "<li>A <strong>postcondition</strong> is something that the function guarantees is true when it finishes.</li>\n",
    "<li>An <strong>invariant</strong> is something that is always true at a particular point inside a piece of code.</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "<h2 id=\"test-driven-development\">Test-Driven Development</h2>\n",
    "<ul>\n",
    "<li>An assertion checks that something is true at a particular point in the program.</li>\n",
    "<li>The next step is to check the overall behavior of a piece of code, i.e., to make sure that it produces the right output when it&rsquo;s given a particular input.</li>\n",
    "<li>For example, suppose we need to find where two or more time series overlap. The range of each time series is represented as a pair of numbers, which are the time the interval started and ended.</li>\n",
    "<li>The output is the largest range that they all include:</li>\n",
    "</ul>\n",
    "<p><img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"images/range_overlap.png\" alt=\"Ranges -3 to 5, 0 to 4.5, -1/5 to 2.0, 0.0 to 2.0\" width=\"441\" height=\"196\" /></p>\n",
    "<p>Most novice programmers would solve this problem like this:</p>\n",
    "<ol>\n",
    "<li>Write a function <code class=\"language-plaintext highlighter-rouge\">range_overlap</code>.</li>\n",
    "<li>Call it interactively on two or three different inputs.</li>\n",
    "<li>If it produces the wrong answer, fix the function and re-run that test.</li>\n",
    "</ol>\n",
    "<p>This clearly works &mdash; but it isn't repeatable &mdash; this is a better way:</p>\n",
    "<ol>\n",
    "<li>Write a short function for each test.</li>\n",
    "<li>Write a <code class=\"language-plaintext highlighter-rouge\">range_overlap</code> function that should pass those tests.</li>\n",
    "<li>If <code class=\"language-plaintext highlighter-rouge\">range_overlap</code> produces any wrong answers, fix it and re-run the test functions.</li>\n",
    "</ol>\n",
    "<p>Writing the tests <em>before</em> writing the function they exercise is called test-driven development (TDD). Its advocates believe it produces better code faster because:</p>\n",
    "<ol>\n",
    "<li>If people write tests after writing the thing to be tested, they are subject to confirmation bias, i.e., they subconsciously write tests to show that their code is correct, rather than to find errors.</li>\n",
    "<li>Writing tests helps programmers figure out what the function is actually supposed to do.</li>\n",
    "</ol>\n",
    "<p>Here are three test functions for <code class=\"language-plaintext highlighter-rouge\">range_overlap</code>:</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'range_overlap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m) ]) \u001b[39m==\u001b[39m (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m-\u001b[39m\u001b[39m2.0\u001b[39m, \u001b[39m3.0\u001b[39m), (\u001b[39m2.0\u001b[39m, \u001b[39m4.0\u001b[39m) ]) \u001b[39m==\u001b[39m (\u001b[39m2.0\u001b[39m, \u001b[39m3.0\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m), (\u001b[39m0.0\u001b[39m, \u001b[39m2.0\u001b[39m), (\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m, \u001b[39m1.0\u001b[39m) ]) \u001b[39m==\u001b[39m (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'range_overlap' is not defined"
     ]
    }
   ],
   "source": [
    "assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)\n",
    "assert range_overlap([ (-2.0, 3.0), (2.0, 4.0) ]) == (2.0, 3.0)\n",
    "assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>The error is actually reassuring: we haven&rsquo;t written <code class=\"language-plaintext highlighter-rouge\">range_overlap</code> yet, so if the tests passed, it would be a sign that someone else had and that we were accidentally using their function.</li>\n",
    "<li>And as a bonus of writing these tests, we&rsquo;ve implicitly defined what our input and output look like: we expect a list of pairs as input, and produce a single pair as output.</li>\n",
    "<li>Something important is missing, though. We don&rsquo;t have any tests for the case where the ranges don&rsquo;t overlap at all or two segments that touch at their endpoints</li>\n",
    "</ul>\n",
    "<div class=\"language-python highlighter-rouge\">\n",
    "<div class=\"highlight\">\n",
    "<pre class=\"highlight\"><code><span class=\"k\">assert</span> <span class=\"n\">range_overlap</span><span class=\"p\">([</span> <span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mf\">5.0</span><span class=\"p\">,</span> <span class=\"mf\">6.0</span><span class=\"p\">)</span> <span class=\"p\">])</span> <span class=\"o\">==</span> <span class=\"err\">???<br /><span class=\"k\">assert</span> <span class=\"n\">range_overlap</span><span class=\"p\">([</span> <span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">2.0</span><span class=\"p\">)</span> <span class=\"p\">])</span> <span class=\"o\">==</span> ???</span>\n",
    "</code></pre>\n",
    "</div>\n",
    "</div>\n",
    "<ul>\n",
    "<li>What should <code class=\"language-plaintext highlighter-rouge\">range_overlap</code> do in this case: fail with an error message, produce a special value like <code class=\"language-plaintext highlighter-rouge\">(0.0, 0.0)</code> to signal that there&rsquo;s no overlap, or something else?</li>\n",
    "<li>Writing the tests first helps us figure out which is best <em>before</em> we begin coding.</li>\n",
    "<li>Since we&rsquo;re planning to use the range this function returns as the X axis in a time series chart, we decide that:</li>\n",
    "</ul>\n",
    "<ol>\n",
    "<li style=\"list-style-type: none;\">\n",
    "<ol>\n",
    "<li>every overlap has to have non-zero width, and</li>\n",
    "<li>we will return the special value <code class=\"language-plaintext highlighter-rouge\">None</code> when there&rsquo;s no overlap.</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "<ul>\n",
    "<li>our last two tests should be:</li>\n",
    "</ul>\n",
    "<div class=\"language-python highlighter-rouge\">\n",
    "<div class=\"highlight\">\n",
    "<pre class=\"highlight\"><code><span class=\"k\">assert</span> <span class=\"n\">range_overlap</span><span class=\"p\">([</span> <span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mf\">5.0</span><span class=\"p\">,</span> <span class=\"mf\">6.0</span><span class=\"p\">)</span> <span class=\"p\">])</span> <span class=\"o\">==</span> <span class=\"bp\">None</span>\n",
    "<span class=\"k\">assert</span> <span class=\"n\">range_overlap</span><span class=\"p\">([</span> <span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">2.0</span><span class=\"p\">)</span> <span class=\"p\">])</span> <span class=\"o\">==</span> <span class=\"bp\">None</span>\n",
    "</code></pre>\n",
    "</div>\n",
    "</div>\n",
    "<h4>Coding the Function</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_overlap(ranges):\n",
    "    \"\"\"Return common overlap among a set of [left, right] ranges.\"\"\"\n",
    "    max_left = 0.0\n",
    "    min_right = 1.0\n",
    "    for (left, right) in ranges:\n",
    "        max_left = max(max_left, left)\n",
    "        min_right = min(min_right, right)\n",
    "    return (max_left, min_right)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>We put our tests into a single method so we can re-run our tests with one function call.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m), (\u001b[39m0.0\u001b[39m, \u001b[39m2.0\u001b[39m), (\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m, \u001b[39m1.0\u001b[39m) ]) \u001b[39m==\u001b[39m (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[39massert\u001b[39;00m range_overlap([]) \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m test_range_overlap()\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mtest_range_overlap\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_range_overlap\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m), (\u001b[39m5.0\u001b[39m, \u001b[39m6.0\u001b[39m) ]) \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m), (\u001b[39m1.0\u001b[39m, \u001b[39m2.0\u001b[39m) ]) \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39massert\u001b[39;00m range_overlap([ (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m) ]) \u001b[39m==\u001b[39m (\u001b[39m0.0\u001b[39m, \u001b[39m1.0\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_range_overlap():\n",
    "    assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None\n",
    "    assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None\n",
    "    assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)\n",
    "    assert range_overlap([ (-2.0, 3.0), (2.0, 4.0) ]) == (2.0, 3.0)\n",
    "    assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)\n",
    "    assert range_overlap([]) == None\n",
    "\n",
    "test_range_overlap()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>The first test that was supposed to produce <code class=\"language-plaintext highlighter-rouge\">None</code> fails, so we know something is wrong with our function.</li>\n",
    "<li>We <em>don&rsquo;t</em> know whether the other tests passed or failed because Python halted the program as soon as it spotted the first error.</li>\n",
    "<li>If we trace the behavior of the function with that input, we realize that we&rsquo;re initializing <code class=\"language-plaintext highlighter-rouge\">max_left</code> and <code class=\"language-plaintext highlighter-rouge\">min_right</code> to 0.0 and 1.0 respectively, regardless of the input values.</li>\n",
    "<li>This violates another important rule of programming: <em>always initialize from data</em>.</li>\n",
    "<li>Try fixing the code so the unit tests run without errors.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
